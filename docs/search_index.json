[["index.html", "R Course Chapter 1 Introduction to R and Basic Programming Concepts 1.1 Overview of R Programming 1.2 Introduction to the R ecosystem 1.3 Setting Up R Environment 1.4 Hands-on Exercise", " R Course YOUR NAME HERE 2024-08-26 Chapter 1 Introduction to R and Basic Programming Concepts 1.1 Overview of R Programming 1.1.1 Introduction to R R is a programming language particularly designed for statistics and data analysis. It was invented the statisticians Robert Gentleman and Ross Ihaka in 1990 and now its the one of the most widely used in data science community. The language is open-source, this has allowed extensive customization and adaptability for research and data analysis. Here are some of the Key features of R; Statistical Computing: R has various tools specifically for statistics like time-series, clustering, classification ,and linear and non-linear models. Data Wrangling and Analysis: R has extensive libraries like dplyr and ggplot for data manipulation and visualizations respectively. Users are able to clean, transform and present the data inform of charts in a meaningful way for better insights with the help of these libraries. Reproducibility: R language allows reproducible research such that the code and the results can be stored inform of scripts, markdown, notebooks and bookdown. Work done in R can be easily shared and reviewed enabling easy collaboration and transparency in work. Comprehensive Ecosystem: R has the CRAN(Comprehensive R Archive Network) that hosts numerous packages for different tasks like machine learning, data visualization, finances, bioinformatics and more. Versatility: R can be used with other tools like other programming languages, for instance Python, SQL etc. This allows seamless integration in the wide range of data ecosystems. 1.1.2 Importance of R in Data Analysis This are some of the features that sets R apart in the data community; Large Community and Support: There is a large online community for data scientist and other researchers who use R. The community has contributed to the development of various packages , continuous improvements, support and extensive documentation. This has made it possible and easy for new users and experienced users to find solution for the complex tasks. Versatility: Data Analysis in R is applicable in various industries like health, finance, government and academia. This allows it to handle diverse data types and analysis needs. Specialization on Statistical Analysis: Most programming languages were designed to be general purpose but R was designed specifically for statistics. This ensures its users have access to the most relevant and important tools in the data analysis tasks. Advanced Visualization: R has one of the best visualization capabilities like dashboards apps, interactive charts. Also, it can be used to generate the most aesthetically pleasing chart crucial for effective communication and decision making. 1.1.3 Application of R in Various Industries R is widely applicable in various industries due to its robust statistical capabilities, open source nature and the extensive library how is important in different industries; R is the go-to tool in the field of academia and research especially in data analysis, social and environmental science research(psychology, economics and climate change), reproducible research and statistical research. In the Manufacturing industries, R can be used to optimize operations like supply chain, quality control and cost reduction. The Governments can use R for data driven research like demographics, economic policy analysis, health and social policy.Forecasts can be made using R that will enable the research. The finance and banking industries use R for complex tasks like algorithmic trading, portfolio optimization, credit scoring and risk management. R is applicable is essential in the health industry in areas like clinical trials and bioinformatics, tracking the spread of diseases(epidemiology) and help in health policy making. R is also applicable in many other industries like marketing, sports and entertainment to name but a few. As industries continue to embrace data-driven strategies, R’s role in analytics and decision-making will only continue to grow. 1.2 Introduction to the R ecosystem 1.2.1 R Studio Rstudio is an integrated development environment(IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution as well as tools for plotting history, debugging and work space management. R studio is an open source software from posit and can be freely be downloaded from https://posit.co/download/rstudio-desktop/. This link has all the installation files for Mac, Linux and Windows. You will download the installation file and install based on your computer operating system. 1.2.2 CRAN 1.3 Setting Up R Environment 1.3.1 Installation of R and RStudio Step-by-step guide to downloading and installing R and RStudio on participants’ computers. Overview of the installation process on different operating systems (Windows, macOS, Linux). 1.3.2 Introduction to RStudio Interface The image above is for R code in R Studio. Each quadrant has its own function. text editor: serves as the primary interface for writing and editing R scripts, Markdown documents, and other text-based files stand input/output (console/terminal/jobs): It is the bottom left quadrant in R Studio that serves as a command-line interface where you can directly interact with R such as code execution and output display. all data and its properties quadrants: It is the top right quadrant in Rstudio that is typically the “Environment” pane, which provides information and tools for managing your R environment such as data importation, display of variables. plots and file directory structure: The bottom right quadrant in RStudio typically houses the “Files”, “Plots”, “Packages”, “Help”, and “Viewer” tabs. 1.3.3 Basic R Syntax and Commands R syntax has specific rules that govern how code is written in R. Understanding these concepts makes a programmer to write clear and error-free code. These are some of the syntax rules that govern how code is written in R. Case sensitivity The R syntax distinguishes between the uppercase letter and the lowercase letter. A variable written in uppercase is different as the variable written in lowercase even the words mean the same. For instance let’s take the variable “age” and store it 15, and another variable “AGE” and store it 27 and see their outputs. # Different variables due to case sensitivity age &lt;- 15 AGE &lt;- 27 print(age) # Outputs: 15 ## [1] 15 print(AGE) # Outputs: 27 ## [1] 27 You can see that above here the variable age and AGE are treated as different. Assignment Operators R has several different methods to assign a value to a variable. They include; Equal Sign(‘=’): This assignment operator is always used when assigning the function arguments but can used in general assignments. age = 21 #variable `age` is assigned to 21 ii. **Left Arrow(&#39;&lt;-&#39;)**: This is the common type of assignment operator. The direction of the arrow points to the variable age &lt;- 10 # variable &#39;age&#39; assigned to 10 iii. **Right Arrow(&#39;-&gt;&#39;)**: This is just like the right arrow operator however the direction of the arrow is reversed. The arrow should still point to the direction of the variable. 27 -&gt; age # arrow points to the direction of the variable, age Use of symbols The R language has several symbols that have specific meaning important when writing code. The Hash(‘#’): Is used for comments. R ignores any text that follows # in the same line # This is a comment Dollar Sign (’$`): Used to access elements of a list or column values in a data frame df &lt;- data.frame(a = 1:3, b = 4:6) df$a # Accesses column &#39;a&#39; in the data frame ## [1] 1 2 3 Square brackets ([]): They are used for indexing vectors, lists, matrices and data frames v &lt;- c(10, 20, 30) v[3] # Accesses the third element (20) ## [1] 30 Curly braces ({}): Used to group multiple expressions, for instance in loops and conditional statements. In this case we will use a if else conditional statement to show how curly braces are used x &lt;- 2 if (x &gt; 0) { print(&quot;Positive number&quot;) } ## [1] &quot;Positive number&quot; Left arrow (‘&lt;-’) and the right arrow (‘-&gt;’): As mentioned earlier, these are assignment operators Brackets ‘()’: Used for function calls and grouping expressions sum(1, 2, 3) ## [1] 6 There are more symbols used in R especially in mathematical operators and advanced concepts that will be later introduced in the course. Reserved Words R has set of reserved words that have special meaning like identifiers and function names. These words cannot be used as variable names. if, else, repeat, while, function, TRUE, FALSE, NA and NULL are just but a few examples of reserved words. Whitespace R generally ignores whitespace (spaces, tabs, newlines) between elements, except within character strings or where it would change the meaning of the code. Proper use of whitespace improves code readability. x &lt;- 5 + 3 # Valid y &lt;-5+3 # Also valid, but less readable 1.4 Hands-on Exercise "],["basic-data-types-and-structures.html", "Chapter 2 Basic Data Types and Structures 2.1 Data types 2.2 Data Structures", " Chapter 2 Basic Data Types and Structures 2.1 Data types There are different kinds of values in R that can be manipulated in variables in R. class()function is used to check the data type of a value or a variable. Different data types include; Numeric These represent numeric values such as integers and decimals. They are used for mathematical expressions and quantitative data analysis. The below code finds the data type of variable a which is assigned 23.5 and returns numeric. a=23.5 class(a) #check the data type of a ## [1] &quot;numeric&quot; a whole number without without a decimal is also numeric for instance 45, 8, 0 and 73. Run the code chunks below to inspect to find the code of each value class(45) ## [1] &quot;numeric&quot; class(8) ## [1] &quot;numeric&quot; class(0) ## [1] &quot;numeric&quot; class(73) ## [1] &quot;numeric&quot; Activity Answer the questions below; Find the data type of 98.03 using class() function. Assign the value 98.03 to variable height and find data type of height. # I. Find the data type of 98.03 using class() function # CODE HERE # II. Assign the value `98.03` to variable `height` and find its data type # CODE HERE Integers They represent whole numbers without any any decimals and are a subclass of numeric. L is added at the end of a whole number to indicate that it is an integer. a=23L #add L to show it is an integer class(a) ## [1] &quot;integer&quot; Lets store age as an integer. Note the ‘L’ after the number 27 age = 27L class(age) ## [1] &quot;integer&quot; Activity Answer the questions below; Find the data type of any whole number using class() function. Remember to add L after the digits There are 27 goats in a field, assign the quantity of goats to a variable goats and find the data type of the variable goats. # I. Find the data type of any whole number using `class()` function. **Remember to add `L` after the digits** # CODE HERE # II. There are 27 goats in a field, assign the quantity of goats to a variable `goats` and find the data type of the variable `goats`. # CODE HERE Characters They represent text strings such as names, sentences and labels. They are enclosed in ” or ’. a=&quot;DNA&quot; class(a) ## [1] &quot;character&quot; Lets use name as a character name = &quot;Pragya&quot; class(name) ## [1] &quot;character&quot; for an object item = &quot;car&quot; # &quot;car&quot; is stored in a variable item class(item) ## [1] &quot;character&quot; Character data types can have empty spaces in between, for instance; fullname = &quot;Salman Khan&quot; class(fullname) ## [1] &quot;character&quot; Activity In the code cell below; Find the data type of the value \"school\" using the class() function. Assign your first name to a variable firstname and find its data type. Remember to enclose it in quotation marks Assign your full names to a variable full_name and find its data type. For instance if your name is “Vipin Patel” assign it like;full_name = \"Vipin Patel\" and find its data type. Remember to enclose the value in quotation marks since its a character data type # I. Find the data type of the value `&quot;school&quot; # CODE HERE # Assign your first name to variable first name and find its data type # CODE HERE # Assign your full names to a variable full_name and finds data type # CODE HERE Logical They represent boolean values which has only distinct value; TRUE or FALSE. a=TRUE #logical data types is either TRUE or FALSE only class(a) ## [1] &quot;logical&quot; changing it to FALSE b = FALSE class(b) ## [1] &quot;logical&quot; Activity Assign a TRUE to a variable grateful and find the data type of the variable. # Assign a `TRUE` to a variable `grateful` and find its data type ## CODE HERE Complex They represent complex numbers with real and imaginary parts a=2+3i # Complex data types have &#39;i&#39; at the end of each number class(a) ## [1] &quot;complex&quot; 2 is the real part while 3i is the imaginary part. Also, complex numbers can be created by complex() function with real and imaginary as the arguments. z = complex(real = 3, imaginary = 7) print(z) #show the comlex value ## [1] 3+7i class(z) #confirm that it is a complex number ## [1] &quot;complex&quot; Lets try another values to fit to the complex data type 2+5i z = complex(real=2, imaginary = 5) print(z) ## [1] 2+5i class(z) ## [1] &quot;complex&quot; 7 + 6i m=complex(real=7, imaginary = 6) print(m) ## [1] 7+6i class(m) ## [1] &quot;complex&quot; 4i - 1 b = 4i-1 print(b) ## [1] -1+4i class(b) ## [1] &quot;complex&quot; Complex data types can include the imaginary part only without real number, R will assume the real part to be 0(zero). For instance; h = 3i print(h) ## [1] 0+3i class(h) ## [1] &quot;complex&quot; Activity Find the data type of the following values; One of them is a numeric element 3i + 8 5 - 1i 4i 12 #i. 3i + 8 # CODE HERE # ii. 5 - 1i # CODE HERE # iii. 4i # CODE HERE # iv. 12 # CODE HERE Raw They represent a vector of bytes in their natural form. They are used in storing binary data. Example; a=charToRaw(&quot;DNA&quot;) print(a) ## [1] 44 4e 41 class(a) ## [1] &quot;raw&quot; # convert back to character b=rawToChar(a) class(b) ## [1] &quot;character&quot; “Hello world” can be represented as in the results below when converted to raw data type binary_data = charToRaw(&quot;Hello World&quot;) print(binary_data) ## [1] 48 65 6c 6c 6f 20 57 6f 72 6c 64 class(binary_data) ## [1] &quot;raw&quot; Numeric can also be represented as raw vectors; age=as.raw(27) print(age) ## [1] 1b class(age) ## [1] &quot;raw&quot; Activity Convert the following values to raw data types; Hint: use charToRaw() function for character data types and as.raw() to other data types. \"Vipin\" 27 69.0 FALSE 12L # i. &quot;Vipin&quot; # CODE HERE # ii. 27 # CODE HERE # iii. 69.0 # CODE HERE # iv. FALSE # CODE HERE # v. 12L # CODE HERE 2.2 Data Structures This is the organization of data into one or multiple data values in specific structures. Different types of data structures in R include; Vector Matrix Data frame 2.2.1 Vector A vector is a single entity consisting of a collection of things. They are versatile providing a basis of many operations in statistics and data manipulation hence it is important to have knowledge of vectors for effective programming in R. Vectors are created using a c() function, here is an example of a vector. marks = c(23, 67, 98, 34, 98, 21) print(marks) # print to the console ## [1] 23 67 98 34 98 21 Activity Create a vector named ages and insert the following values 21, 32, 22, 24, 27, 54, 20, 13 and print it out on the console # vector ages with elements 21, 32, 22, 24, 27, 54, 20, 13 # CODE HERE The class function is utilized to determine the data types present within vector data values. marks = c(23, 67, 98, 34, 98, 21) class(marks) ## [1] &quot;numeric&quot; The vector “marks” consist of only numeric values is.vector function is used to check if the variable is a vector. It will return a Boolean value, TRUE if the variable in question is truly a vector while FALSE if otherwise. marks = c(23, 67, 98, 34, 98, 21) is.vector(marks) ## [1] TRUE unlike matrix and data frame, vector has no dimension marks = c(23, 67, 98, 34, 98, 21) dim(marks) ## NULL length() function is used to count number of elements in vectors. In our case vector marks, marks = c(23, 67, 98, 34, 98, 21) has six elements, therefore, length() command will return 6. marks = c(23, 67, 98, 34, 98, 21) length(marks) ## [1] 6 Activity Create a vector named height with its elements/values as 120.1, 118, 123.4, 130.8, 115.2 and do the following; print it out to the console using print() function. find the data type of its elements using class() function use is.vector() function to find if its really a vector count the number of elements in the vector using length() function. #Create a vector named `height` with its elements/values as `120.1, 118, 123.4, 130.8, 115.2` and do the following; # CODE HERE # print it out # CODE HERE # find the data type of its elements # CODE HERE # find if its really a vector # CODE HERE # count the number of elements in the vector # CODE HERE Index is the position of an element in a vector, in R it starts at index 1 - lets say we find the third element by index 3 marks = c(23, 67, 98, 34, 98, 21) marks[3] ## [1] 98 value “98” is at index 3, or the third in the vector. The first value/element of a vector is indexed 1, for instance if we find the first value in the vector marks. marks = c(23, 67, 98, 34, 98, 21) marks[1] #returns the first value ## [1] 23 The sequence goes on, the second, third, fourth, fifth … values are indexed as , 2, 3, 4, 5… respectively. i.e the n^th value is indexed as n. Vectors can also be sliced to obtain values over a range of indices. For instance the code below shows how to retrieve the from the second to the fourth values as a vector marks = c(23, 67, 98, 34, 98, 21) print(marks[2:4]) ## [1] 67 98 34 is.vector(marks[2:4]) # confirm if the retrieved values are in a vector ## [1] TRUE An element at a specific index in a vector can be excluded by adding a - sign before the index value. marks = c(23, 67, 98, 34, 98, 21) marks[-2] #exclude the element at index 2 ## [1] 23 98 34 98 21 rev() command is used to reverse the order of elements in a vector marks = c(23, 67, 98, 34, 98, 21) rev(marks) ## [1] 21 98 34 98 67 23 Activity Create a vector named ages and insert the following values; 13, 59, 27, 22, 19, 31, 43. Use it to answer the questions below. Print out the vector ages to the console Store the third element in a variable called my_age and print it out. Extract the values from the second to the fifth element and print them out. Exclude the third element Reverse the order of the elements in the vector. # Create a vector named `ages` and insert the following values; `13, 59, 27, 22, 19, 31, 43` # CODE HERE # i. Print out the vector `ages` to the console # CODE HERE # ii. Store the third element in a variable called `my_age` and print it out. # CODE HERE # iii. Extract the values from the second to the fifth element and print them out. # CODE HERE # iv. Exclude the third element # CODE HERE # v. Reverse the order of the elements in the vector. # CODE HERE 2.2.1.1 Mathematical Operations in a vector The summary/descriptive statistics are calculated by summary() command. marks = c(23, 67, 98, 34, 98, 21) summary(marks) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 21.00 25.75 50.50 56.83 90.25 98.00 sum(), median(), and mean() are used to calculate the total, median, average and the standard deviation of the values in a vector marks = c(23, 67, 98, 34, 98, 21) print(&quot;MARKS&quot;) ## [1] &quot;MARKS&quot; print(paste(&quot;TOTAL: &quot;, sum(marks))) ## [1] &quot;TOTAL: 341&quot; print(paste(&quot;MEDIAN: &quot;, median(marks))) ## [1] &quot;MEDIAN: 50.5&quot; print(paste(&quot;AVERAGE: &quot;, mean(marks))) ## [1] &quot;AVERAGE: 56.8333333333333&quot; Vector multiplication and division - vectors can be multiplied or divided by a scalar value of another vector of the same length and numeric data type. For instance, the vector marks=c(23, 67, 98, 34, 98, 21) is being multiplied by a scalar value 2, that will multiply each element in a vector by two. marks = c(23, 67, 98, 34, 98, 21) # Multiply each element in the vector by 2 double_marks =2 * marks marks ## [1] 23 67 98 34 98 21 double_marks ## [1] 46 134 196 68 196 42 The values in the vector marks can also be scaled down to a half when multiplied by a scalar value 0.5. marks = c(23, 67, 98, 34, 98, 21) # Multiply by 0.5 to scale the marks by a half half_marks =0.5 * marks marks ## [1] 23 67 98 34 98 21 half_marks ## [1] 11.5 33.5 49.0 17.0 49.0 10.5 Alternatively, instead of multiplying the vector by 0.5, it can be divided by 2 a scalar value two. This is what is referred to as vector division. marks = c(23, 67, 98, 34, 98, 21) # Scale down the marks by a half by dividing by 2 instead of multiplying by 0.5 half_marks = marks/2 half_marks ## [1] 11.5 33.5 49.0 17.0 49.0 10.5 Activity Create a vector with the following values; 67, 55, 60, 59, 57.2, 71, 62, 66, 70 and name the vector weights. Use the variable weights to solve the following problems Calculate the; i. median weight ii. mean(average) weight iii. the total weight when summed together Calculate the summary statistics using the summary() function. Add 10 to variable weights and the answer added_weights. Subtract 15 to weights and name it reduced_weights. Scale the weights by multiplying the vector by 1.5. ’ Scale down the weights to a third by dividing the vector by 3. # Create vector weights from 67, 55, 60, 59, 57.2, 71, 62, 66, 70 # CODE HERE ## a. Calculate the; ### i. median weight # CODE HERE ### ii. mean(average) weight # CODE HERE ### iii. the total weight when summed together # CODE HERE ## b. Calculate the summary statistics using the `summary()` function. # CODE HERE ## c. Add 10 to variable `weights` and the answer `added_weights`. # CODE HERE ## d. Subtract 15 to `weights` and name it `reduced_weights`. # CODE HERE ## e. Scale the weights by multiplying the vector by 1.5. &#39; # CODE HERE ## f. Scale down the weights to a third by dividing the vector by 3. # CODE HERE Vector by vector multiplication and division Two or more vectors of numeric values of the equal length can be multiplied or divided by each other. The example below demonstrates vector by vector multiplication of vector a; 3, 5, 1 and vector b: 7, 3, 9. Each value is multiplied by a value of a corresponding index in the next vector such that; 3 is multiplied by 7 to be 21 5 is multiplied by 3 to be 15 1 is multiplied by 9 to be 9. The resultant vector is now 21 15 9. a = c(3, 5, 1) b = c(7, 3, 9) ab = a*b ab ## [1] 21 15 9 ba = b*a # is the same as ab ba ## [1] 21 15 9 The same vectors can also be divided by each other provided they are of the same length and all have numeric values. The order of vector division, for instance in the first case vector a is divided by vector b such that; 3 is divided by 7 to be 0.4285714 5 is divided by 3 to be 1.6666667 1 is divided by 9 to be 0.1111111. The resultant vector is now 0.4285714 1.6666667 0.1111111. # First case a = c(3, 5, 1) b = c(7, 3, 9) # Divide vector a by b abdiv=a/b abdiv ## [1] 0.4285714 1.6666667 0.1111111 , and in the second case the order of vector division is reversed by vector b being divided by a (b/a instead of a/b) such that; 7 is divided by 3 to be 2.333333 3 is divided by 5 to be 0.600000 9 is divided by 1 to be 9.000000. The resultant vector is now 2.333333 0.600000 9.000000. # Second case a = c(3, 5, 1) b = c(7, 3, 9) # Divide vector b by a badiv=b/a badiv ## [1] 2.333333 0.600000 9.000000 However, when multiplying vectors of unequal length the shorter one is replicated to match the longer vector. It will then return a warning. The case below shows how vector e=c(1,2,3,4,5) and f=c(1,2) are multiplied. vector f=c(1,2) will be replicated to match the length of vector e, therefore, vector f will be f=c(1,2,1,2,1). The process of vector by vector multiplication will be followed. e=c(1,2,3,4,5) f=c(1,2) ef = e*f #it shows an error ## Warning in e * f: longer object length is not a multiple of shorter object ## length ef #shows results since f is replicated to match e as f=c(1,2,1,2,1) ## [1] 1 4 3 8 5 Multiple vectors can be concatenated/combined to come up with one giant vector a ## [1] 3 5 1 b ## [1] 7 3 9 z=c(a,b,a) #concatenates the vectors z ## [1] 3 5 1 7 3 9 3 5 1 Activity Create two vectors, vector1;4, 6, 12, 7 and vector2:7, 3, 5, 10. Use the two vectors to solve the following questions. Create vector3 by multiplying vector1 and vector2. Print it out. Create vector4a by diving vector1 by vector2. Print it out. Create vector4b by dividing vector2 by vector1. Print it out. Is there a difference between vector4a and vector4b? If there is, what brought the difference? Write the answer as a comment. Create another vector5; 4, 6 and multiply it with vector1 to come up with vector6. Print it out. Concatenate vector1, vector2 and vector5 to come up with a giant_vector. Print it out. # Create vector1 and vector2 as instructed # CODE HERE ## i. Create `vector3` by multiplying `vector1` and `vector2`. Print it out. # CODE HERE ## ii. Create `vector4a` by diving `vector1` by `vector2`. Print it out. # CODE HERE ## iii. Create `vector4b` by dividing `vector2` by `vector1`. Print it out. # CODE HERE ## iv. Is there a difference between `vector4a` and `vector4b`? If there is, ## what brought the difference? Write the answer as a comment. # COMMENT HERE ## v. Create another `vector5`; `4, 6` and multiply it with `vector1` to come up ## with `vector6`. Print it out. # CODE HERE ## vi. Concatenate `vector1`, `vector2` and `vector5` to come up with a ## `giant_vector`. Print it out. # CODE HERE 2.2.1.2 Character Vectors Vectors can also contain character data types for instance my_name = c(&quot;My&quot;, &quot;name&quot;, &quot;is&quot;, &quot;Vipin&quot;) my_name[5] = &quot;Singh&quot; #insert at the end my_name ## [1] &quot;My&quot; &quot;name&quot; &quot;is&quot; &quot;Vipin&quot; &quot;Singh&quot; Combining the vectors to a single string. For instance the vector my_name = c(\"My\", \"name\", \"is\", \"Vipin\") is combined to \"My name is Vipin\". The collapse argument is used as below; print(paste(my_name, collapse=&quot; &quot;)) ## [1] &quot;My name is Vipin Singh&quot; Calculate the summary/descriptive statistics of the vector by function summary(). It finds; Count/length Class (data type) Mode summary(my_name) ## Length Class Mode ## 5 character character 2.2.1.3 Vectors with mixed data types A vector can also consist of characters values and numeric values for instance numbers=c(1,&quot;two&quot;, 3, &quot;three&quot;) numbers ## [1] &quot;1&quot; &quot;two&quot; &quot;3&quot; &quot;three&quot; however the numeric elements in the vector are recognized by R as character data type. They can be converted to numeric by; as.numeric(numbers[1]) + 2 ## [1] 3 the integers can be converted by; as.integer(numbers[1]) ## [1] 1 2.2.1.4 Named Vectors Variable names can be assigned to vectors like; named_vector=c(EcoR1=&quot;GAATTC&quot;, HindIII=&quot;AAGCTT&quot;, Pst1=&quot;CTGCAG&quot;) named_vector ## EcoR1 HindIII Pst1 ## &quot;GAATTC&quot; &quot;AAGCTT&quot; &quot;CTGCAG&quot; to access the names of the values is; names(named_vector) ## [1] &quot;EcoR1&quot; &quot;HindIII&quot; &quot;Pst1&quot; A vector element can be accessed using its name named_vector[&quot;EcoR1&quot;] # find the value of a vector by its name ## EcoR1 ## &quot;GAATTC&quot; 2.2.1.5 Generating number series as vectors The seq function in R is used to generate sequences of numbers. It takes several arguments, including from, to, by, and length.out, among others, to specify the range and increment of the sequence. Here’s a brief overview of its usage: from: The starting value of the sequence. to: The end value of the sequence. # Generate a sequence from 1 to 10 series = seq(from=1, to=20) series ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # It can also be written as series = seq(1,20) series ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class(series) ## [1] &quot;integer&quot; by: The increment between consecutive values in the sequence. # generate numbers 0 to 10 incremented by 0.5 series3=seq(0, 10, by=0.5) series3 ## [1] 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 ## [16] 7.5 8.0 8.5 9.0 9.5 10.0 length: The desired length of the sequence. # generate 10 numbers from 0 to 6 series4=seq(0, 6, length=10) series4 ## [1] 0.0000000 0.6666667 1.3333333 2.0000000 2.6666667 3.3333333 4.0000000 ## [8] 4.6666667 5.3333333 6.0000000 seq(0, 6) ## [1] 0 1 2 3 4 5 6 along.with: An optional vector argument specifying the length and names of the output sequence. # Generate a sequence along with a vector seq(along.with = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)) ## [1] 1 2 3 2.2.1.6 Null data points in vectors NA data (Not available or blank) for instance marks=c(78,65, 98, 87, 89, NA) sum(is.na(marks)) #Count the null values in a vector ## [1] 1 Other inbuilt functions for mathematical operations cannot be done if Null values exists in a vector unless they are removed/ignored #sum(marks) #returns an error sum(marks, na.rm = TRUE) #remove null values before calculating the sum ## [1] 417 median(marks, na.rm = TRUE) ## [1] 87 summary(marks, na.rm = TRUE) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 65.0 78.0 87.0 83.4 89.0 98.0 1 2.2.2 Matrix A matrix is a two dimensional data type that contain a single class of data. The code below shows one can produce a matrix from a vector vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) data1 ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 A vector of values 1 to 9 is being converted to a matrix where the values are being arranged column wise by default. A matrix has a multiple dimensions, the most common type of matrix is two dimesnional. vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) # find the dimension of the vector dim(data1) ## [1] 3 3 is.matrix() function is used to confirm if a given variable is a matrix and it return a boolean value. vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) # confirm if `data1` is really a matrix is.matrix(data1) ## [1] TRUE A matrix can also be created row-wise from a vector. vector1 = seq(1, 9) ## create a matrix by row data2=matrix(vector1, ncol=3, byrow=TRUE) data2 # is a transpose of data1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 Matrix is recognized either as a matrix or array by R vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) # find the data type of `data1` class(data1) ## [1] &quot;matrix&quot; &quot;array&quot; To access a specific data point in a matrix, the matrix is indexed by row then column for instance matrix_data[row_index, column_index] vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) # retrieve the value in the third row second column in `data1` data1[3, 2] ## [1] 6 To access a single row, in this case we find the second row which will be returned as a vector vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) row2 = data1[2,] # access row 2 is.vector(row2) #can be accessed by row 2 ## [1] TRUE To access a single column vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) col3=data1[,3] # access column 3 is.vector(col3) #can be accessed by column 3 ## [1] TRUE Count the number of rows in a matrix vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) nrow(data1) ## [1] 3 data1 has 3 rows Count the number of columns in a matrix vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) ncol(data1) ## [1] 3 2.2.2.1 Mathematical Operations in a matrix Matrix Addition Matrix addition can be done by adding a number to the matrix or another matrix of the equal number of rows and columns. vector1 = seq(1, 9) # Convert to matrix ## create by column data1=matrix(vector1, ncol=3) data2 = data1 + 3 data2 ## [,1] [,2] [,3] ## [1,] 4 7 10 ## [2,] 5 8 11 ## [3,] 6 9 12 For instance, the code snippet above demonstrates matrix addition by a numeric value. Adding value 3 to a matrix adds each value in the matrix by 3. To demonstrate a matrix to a matrix addition, we will create two matrices of the equal dimensions then add to each other. data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) print(data1) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 data2 = matrix(seq(1, 18, 2), ncol=3, byrow=TRUE) print(data2) ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 7 9 11 ## [3,] 13 15 17 # Add data1 to data2 resultant_matrix = data1 + data2 resultant_matrix ## [,1] [,2] [,3] ## [1,] 2 5 8 ## [2,] 11 14 17 ## [3,] 20 23 26 Matrix Subtraction The same concept of matrix addition applies to matrix subtraction as well. data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) data3 = data1-1 #reduce each value by 1 data3 ## [,1] [,2] [,3] ## [1,] 0 1 2 ## [2,] 3 4 5 ## [3,] 6 7 8 Subtracting 1 to data1 subtract each value in the matrix by 1. Lets now subtract data1 from data2. data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) data1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 data2 = matrix(seq(1, 18, 2), ncol=3, byrow=TRUE) data2 ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 7 9 11 ## [3,] 13 15 17 resultant_matrix = data2-data1 resultant_matrix ## [,1] [,2] [,3] ## [1,] 0 1 2 ## [2,] 3 4 5 ## [3,] 6 7 8 Matrix Multiplication(scalar) A matrix can be multiplied by a scalar whereby the scalar value multiplies all the cells in the matrix. data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) data1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 data4 = data1*5 data4 ## [,1] [,2] [,3] ## [1,] 5 10 15 ## [2,] 20 25 30 ## [3,] 35 40 45 Matrix multiplication applies a concept of row by column. The row of the first matrix is multiplied with a row of the second matrix. It also known as the dot product. data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) data1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 data2 = matrix(seq(1, 18, 2), ncol=3, byrow=TRUE) data2 ## [,1] [,2] [,3] ## [1,] 1 3 5 ## [2,] 7 9 11 ## [3,] 13 15 17 # Find the product of the two matrices product_matrix = data1 * data2 product_matrix ## [,1] [,2] [,3] ## [1,] 1 6 15 ## [2,] 28 45 66 ## [3,] 91 120 153 Matrix division data1 = matrix(seq(1, 9), ncol=3, byrow=TRUE) data1 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 # Divide `data1` matrix by 2 data5 = data1/2 data5 ## [,1] [,2] [,3] ## [1,] 0.5 1.0 1.5 ## [2,] 2.0 2.5 3.0 ## [3,] 3.5 4.0 4.5 2.2.3 Data frame is a two dimensional data structure, like a 2d array/matrix with rows and columns. Lets convert a matrix into a data frame vector1 = c(1:12) matrix1 = matrix(vector1, ncol=4) #create a matrix from the vector # Adding a column student Students=c(&quot;Pragya&quot;, &quot;Deepika&quot;, &quot;Chandran&quot;) data = data.frame(Students, matrix1) data ## Students X1 X2 X3 X4 ## 1 Pragya 1 4 7 10 ## 2 Deepika 2 5 8 11 ## 3 Chandran 3 6 9 12 The above data shows scores of different students in different subjects. The column names are automatically generated by R, however, the column names can be added as below. vector1 = c(1:12) matrix1 = matrix(vector1, ncol=4) #create a matrix from the vector # Adding a column student Students=c(&quot;Pragya&quot;, &quot;Deepika&quot;, &quot;Chandran&quot;) data = data.frame(Students, matrix1) data ## Students X1 X2 X3 X4 ## 1 Pragya 1 4 7 10 ## 2 Deepika 2 5 8 11 ## 3 Chandran 3 6 9 12 # Create column names headers=c(&quot;Students&quot;, &quot;Geonomics&quot;, &quot;Proteomics&quot;, &quot;Microbiology&quot;, &quot;Biostatistics&quot;) colnames(data)=headers #add column names data ## Students Geonomics Proteomics Microbiology Biostatistics ## 1 Pragya 1 4 7 10 ## 2 Deepika 2 5 8 11 ## 3 Chandran 3 6 9 12 A row wise addition can be performed on a data frame to find the total scores for each student in the four units vector1 = c(1:12) matrix1 = matrix(vector1, ncol=4) #create a matrix from the vector # Adding a column student Students=c(&quot;Pragya&quot;, &quot;Deepika&quot;, &quot;Chandran&quot;) data = data.frame(Students, matrix1) data ## Students X1 X2 X3 X4 ## 1 Pragya 1 4 7 10 ## 2 Deepika 2 5 8 11 ## 3 Chandran 3 6 9 12 ## Add a new column with total marks obtained data$total_marks=rowSums(data[, c(2, 3, 4, 5)]) #add from second to fifth column data ## Students X1 X2 X3 X4 total_marks ## 1 Pragya 1 4 7 10 22 ## 2 Deepika 2 5 8 11 26 ## 3 Chandran 3 6 9 12 30 Find the average score for each student.rowMeans() is used the average of each row/record. vector1 = c(1:12) matrix1 = matrix(vector1, ncol=4) #create a matrix from the vector # Adding a column student Students=c(&quot;Pragya&quot;, &quot;Deepika&quot;, &quot;Chandran&quot;) data = data.frame(Students, matrix1) data ## Students X1 X2 X3 X4 ## 1 Pragya 1 4 7 10 ## 2 Deepika 2 5 8 11 ## 3 Chandran 3 6 9 12 data$average_marks=rowMeans(data[, c(2, 3, 4, 5)]) data # confirm if the new column is added ## Students X1 X2 X3 X4 average_marks ## 1 Pragya 1 4 7 10 5.5 ## 2 Deepika 2 5 8 11 6.5 ## 3 Chandran 3 6 9 12 7.5 "],["data-importing-and-exporting.html", "Chapter 3 Data Importing and Exporting 3.1 Introduction to Data Importing 3.2 Demonstration of Data Importing", " Chapter 3 Data Importing and Exporting 3.1 Introduction to Data Importing Explanation of different data formats (e.g., CSV, Excel, JSON). Overview of R functions for reading data (read.csv(), read_excel(), read.table(), etc.). Loading data in R can be very stressful since every file format has a function to import the data. However, it can be very simple when wel explained. Here are some of the most commonly used data file formats R and their importation;- Comma Separated Value(CSV - .csv) files imported by read.csv(\"filepath\") function Excel(.xlsx) files loaded by read_excel(\"filepath\") function` XML(.xml) imported by read.xml(\"filepath\") function` Javascript Object Notation (JSON) by `read.json(“filepath”)`` There are more data files with different formats that can be used in R, their importation will be explained later in the course. 3.2 Demonstration of Data Importing Importing a CSV file in R There are different formats to import a csv file in R. We will use the read.csv() and read.delim() which are functions from the baseR. "],["data-manipulation.html", "Chapter 4 Data Manipulation 4.1 Basic Data Manipulation 4.2 Data Manipulation with Dplyr 4.3 Chaining", " Chapter 4 Data Manipulation 4.1 Basic Data Manipulation 4.1.1 Introduction to Data Manipulation Data Manipulation is the adjusting, organizing and transforming of the raw data is not a more useful and suitable format for data analysis. These are some of the reasons that make data manipulation mandatory in the data analysis process; Improves the data quality Raw data may be incomplete, messy, containing irrelevant information, errors ,or duplicates that need to be cleaned and rectified. This will ensure the data is reliable thereby preventing incorrect conclusions or decisions. Making Data Usable Sometimes data is collected from different sources that is not ready for analysis. Data Manipulation will transform the data into a structured and consistent format for easy analysis. Enhancing Data Exploration By cleaning the data, analysts explore the data thereby understanding different concepts of the data. Enabling Complex Analysis Some types of analysis require data to be in specific format or structure, for instance the time series analysis require data to be sorted out by date. Supporting Decision Making Data Manipulation ensures that the data that is fed into the system is timely, accurate and reliable for informed decision-making models and relevant reports These are the key tasks in the data manipulation; Cleaning: by removing inaccurate and incomplete data entries. Filtering the data by selecting certain rows or columns based on a certain criteria. Reshaping: Changing the structure of the data for instance pivoting. Merging: Combine multiple data sets into one. Transforming: Modify existing data by mathematical or logical operations. Aggregation: Summarizing the data by performing operations like sum,average and count. 4.1.2 Subsetting and Filtering Data: Subsetting is a data management strategy that involves creating a coherent slice data from different data set for specific use cases. This topic will better be explained practically, therefore we will use the titanic data set. The data set contains information about the passengers on the Titanic, including their age, gender, passenger class, whether they survived and other details. Since the titanic dataset is absent in baseR, the titanic library will be installed by; install.packages(&quot;titanic&quot;) load the library library(&quot;titanic&quot;) The data set will indexed using different indexing techniques such as indexing of a single element, row and column indexing. First we load the data set and view the first few records before indexing data(&quot;titanic_train&quot;) titanic &lt;- titanic_train head(titanic) # view the first few rows of the titanic data set ## PassengerId Survived Pclass ## 1 1 0 3 ## 2 2 1 1 ## 3 3 1 3 ## 4 4 1 1 ## 5 5 0 3 ## 6 6 0 3 ## Name Sex Age SibSp Parch ## 1 Braund, Mr. Owen Harris male 22 1 0 ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 0 ## 3 Heikkinen, Miss. Laina female 26 0 0 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 0 ## 5 Allen, Mr. William Henry male 35 0 0 ## 6 Moran, Mr. James male NA 0 0 ## Ticket Fare Cabin Embarked ## 1 A/5 21171 7.2500 S ## 2 PC 17599 71.2833 C85 C ## 3 STON/O2. 3101282 7.9250 S ## 4 113803 53.1000 C123 S ## 5 373450 8.0500 S ## 6 330877 8.4583 Q Extract a row When subsetting to extract data for a single row the square brackets [ ] will be used with the position of the index you want to extract. Lets extract all the information of the 10th passenger. titanic[10, ] # note the comma after the index 10 ## PassengerId Survived Pclass Name Sex Age ## 10 10 1 2 Nasser, Mrs. Nicholas (Adele Achem) female 14 ## SibSp Parch Ticket Fare Cabin Embarked ## 10 1 0 237736 30.0708 C Also, more indices can be subsetted in the format [i:j, ] where the i is the starting index while j is the ending index respectively. Lets extract the information by subsetting the titanic data from index 7 to 10. titanic[7:10, ] ## PassengerId Survived Pclass ## 7 7 0 1 ## 8 8 0 3 ## 9 9 1 3 ## 10 10 1 2 ## Name Sex Age SibSp Parch ## 7 McCarthy, Mr. Timothy J male 54 0 0 ## 8 Palsson, Master. Gosta Leonard male 2 3 1 ## 9 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27 0 2 ## 10 Nasser, Mrs. Nicholas (Adele Achem) female 14 1 0 ## Ticket Fare Cabin Embarked ## 7 17463 51.8625 E46 S ## 8 349909 21.0750 S ## 9 347742 11.1333 S ## 10 237736 30.0708 C Extract a column When subsetting to extract data for a single column the square brackets [ ] will be used as before, with the position of the index or column name you want to extract. Lets extract all the information of the column Name. titanic[, &quot;Name&quot;] # note the comma before &quot;Name&quot; An index of the column can be used in place of the column name. For instance, the column, “PassengerId” is the first column therefore its index will be 1. Lets subset the column by calling the index. titanic[, 1] # note the comma before the column index Extracting a single element A single element that has a defined position in a data frame, both the row index and the column name/index are called. dataframe[row_index, column index/name] Lets extract the age of the Name of the fifth passenger. titanic[5, &quot;Name&quot;] ## [1] &quot;Allen, Mr. William Henry&quot; Instead of using the column name. Lets use the column index. In the above context, the column “Name” appears at index(is the fourth column). titanic[5, 4] ## [1] &quot;Allen, Mr. William Henry&quot; Subsetting a data set can be done by filtering data based on logical conditions to extract rows that meet certain criteria. They involve comparisons operators such as &gt;, &lt;, ==, != or logical operators like &amp;(and), |(or), ! (not). In this titanic data set we:- Filter based on a single condition Lets find the passengers who survived on the titanic. survivors &lt;- titanic[titanic$Survived == 1, ] head(survivors) # view the first few rows of survivors ## PassengerId Survived Pclass ## 2 2 1 1 ## 3 3 1 3 ## 4 4 1 1 ## 9 9 1 3 ## 10 10 1 2 ## 11 11 1 3 ## Name Sex Age SibSp Parch ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 0 ## 3 Heikkinen, Miss. Laina female 26 0 0 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 0 ## 9 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27 0 2 ## 10 Nasser, Mrs. Nicholas (Adele Achem) female 14 1 0 ## 11 Sandstrom, Miss. Marguerite Rut female 4 1 1 ## Ticket Fare Cabin Embarked ## 2 PC 17599 71.2833 C85 C ## 3 STON/O2. 3101282 7.9250 S ## 4 113803 53.1000 C123 S ## 9 347742 11.1333 S ## 10 237736 30.0708 C ## 11 PP 9549 16.7000 G6 S The above data set consists of titanic passengers who survived. Who were the passengers who boarded the first class on the Titan? first_class_passengers &lt;- titanic[titanic$Pclass == 1, ] head(first_class_passengers) ## PassengerId Survived Pclass ## 2 2 1 1 ## 4 4 1 1 ## 7 7 0 1 ## 12 12 1 1 ## 24 24 1 1 ## 28 28 0 1 ## Name Sex Age SibSp Parch ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 0 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 0 ## 7 McCarthy, Mr. Timothy J male 54 0 0 ## 12 Bonnell, Miss. Elizabeth female 58 0 0 ## 24 Sloper, Mr. William Thompson male 28 0 0 ## 28 Fortune, Mr. Charles Alexander male 19 3 2 ## Ticket Fare Cabin Embarked ## 2 PC 17599 71.2833 C85 C ## 4 113803 53.1000 C123 S ## 7 17463 51.8625 E46 S ## 12 113783 26.5500 C103 S ## 24 113788 35.5000 A6 S ## 28 19950 263.0000 C23 C25 C27 S The above examples, the extracted data set met a single condition. Filtering based on Multiple Conditions Data can be subsetted by filtering based on more than one condition. To demonstrate this, lets find the female passengers who survived. Here there are two conditions;- the passenger must be a female, the passenger must have survived. The resultant data set must meet the above conditions female_survivors &lt;- titanic[titanic$Sex == &quot;female&quot; &amp; titanic$Survived == 1, ] head(female_survivors) #view the first few rows ## PassengerId Survived Pclass ## 2 2 1 1 ## 3 3 1 3 ## 4 4 1 1 ## 9 9 1 3 ## 10 10 1 2 ## 11 11 1 3 ## Name Sex Age SibSp Parch ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 0 ## 3 Heikkinen, Miss. Laina female 26 0 0 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 0 ## 9 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg) female 27 0 2 ## 10 Nasser, Mrs. Nicholas (Adele Achem) female 14 1 0 ## 11 Sandstrom, Miss. Marguerite Rut female 4 1 1 ## Ticket Fare Cabin Embarked ## 2 PC 17599 71.2833 C85 C ## 3 STON/O2. 3101282 7.9250 S ## 4 113803 53.1000 C123 S ## 9 347742 11.1333 S ## 10 237736 30.0708 C ## 11 PP 9549 16.7000 G6 S Lets also add one more condition, the female survivor must be under 18. minor_female_survivors &lt;- titanic[titanic$Sex == &quot;female&quot; &amp; titanic$Survived == 1 &amp; titanic$Age &lt; 18, ] # comma should be after the conditons head(minor_female_survivors) ## PassengerId Survived Pclass Name Sex Age ## 10 10 1 2 Nasser, Mrs. Nicholas (Adele Achem) female 14 ## 11 11 1 3 Sandstrom, Miss. Marguerite Rut female 4 ## NA NA NA NA &lt;NA&gt; &lt;NA&gt; NA ## 23 23 1 3 McGowan, Miss. Anna &quot;Annie&quot; female 15 ## NA.1 NA NA NA &lt;NA&gt; &lt;NA&gt; NA ## NA.2 NA NA NA &lt;NA&gt; &lt;NA&gt; NA ## SibSp Parch Ticket Fare Cabin Embarked ## 10 1 0 237736 30.0708 C ## 11 1 1 PP 9549 16.7000 G6 S ## NA NA NA &lt;NA&gt; NA &lt;NA&gt; &lt;NA&gt; ## 23 0 0 330923 8.0292 Q ## NA.1 NA NA &lt;NA&gt; NA &lt;NA&gt; &lt;NA&gt; ## NA.2 NA NA &lt;NA&gt; NA &lt;NA&gt; &lt;NA&gt; Filtering using Negation The != sign a logical operator that is used to negate a condition. Lets use it to find the passengers who did not survive. non_survivors &lt;- titanic[titanic$Survived != 1, ] tail(non_survivors) # view the last few records ## PassengerId Survived Pclass Name Sex ## 884 884 0 2 Banfield, Mr. Frederick James male ## 885 885 0 3 Sutehall, Mr. Henry Jr male ## 886 886 0 3 Rice, Mrs. William (Margaret Norton) female ## 887 887 0 2 Montvila, Rev. Juozas male ## 889 889 0 3 Johnston, Miss. Catherine Helen &quot;Carrie&quot; female ## 891 891 0 3 Dooley, Mr. Patrick male ## Age SibSp Parch Ticket Fare Cabin Embarked ## 884 28 0 0 C.A./SOTON 34068 10.500 S ## 885 25 0 0 SOTON/OQ 392076 7.050 S ## 886 39 0 5 382652 29.125 Q ## 887 27 0 0 211536 13.000 S ## 889 NA 1 2 W./C. 6607 23.450 S ## 891 32 0 0 370376 7.750 Q Alternatively you can use non_survivors &lt;- titanic[!titanic$Survived == 1, ] Also, lets find the passengers who were not in the third class not_third_class &lt;- titanic[titanic$Pclass != 3, ] head(not_third_class) ## PassengerId Survived Pclass ## 2 2 1 1 ## 4 4 1 1 ## 7 7 0 1 ## 10 10 1 2 ## 12 12 1 1 ## 16 16 1 2 ## Name Sex Age SibSp Parch ## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 0 ## 4 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 0 ## 7 McCarthy, Mr. Timothy J male 54 0 0 ## 10 Nasser, Mrs. Nicholas (Adele Achem) female 14 1 0 ## 12 Bonnell, Miss. Elizabeth female 58 0 0 ## 16 Hewlett, Mrs. (Mary D Kingcome) female 55 0 0 ## Ticket Fare Cabin Embarked ## 2 PC 17599 71.2833 C85 C ## 4 113803 53.1000 C123 S ## 7 17463 51.8625 E46 S ## 10 237736 30.0708 C ## 12 113783 26.5500 C103 S ## 16 248706 16.0000 S Alternatively not_third_class &lt;- titanic[!titanic$Pclass == 3, ] 4.1.3 Sorting Data Sorting is the ordering of elements in a data set (vectors, lists, matrix and data frames) based on a particular criteria. This is a fundamental operation data analysis, as it enables data organization in a meaningful way for easier visualization and interpretation. These are the several functions in Base R that are used in sorting;- sort() Lets create a vector v with five elements Sort the elements in a descending order v = c(43, 82, 11, 73, 34) # Create a vector v1 = sort(v, decreasing = TRUE) #sort the elements in a descending order v1 ## [1] 82 73 43 34 11 to order the same vector in an ascending order the decreasing argument is set to FALSE. v = c(43, 82, 11, 73, 34) # Create a vector v2 = sort(v, decreasing = FALSE) #sort the elements in an ascending order v2 ## [1] 11 34 43 73 82 Also character vectors can be sorted in alphabetical order for instance lets sort the the names, \"Alice\", \"Charlie\", \"Bob\" in the alphabetical order. names &lt;- c(&quot;Alice&quot;, &quot;Charlie&quot;, &quot;Bob&quot;) sorted_names &lt;- sort(names) sorted_names ## [1] &quot;Alice&quot; &quot;Bob&quot; &quot;Charlie&quot; Alternatively, the names can be ordered in the reverse alphabetical order when the decreasing argument is set to TRUE. names &lt;- c(&quot;Alice&quot;, &quot;Charlie&quot;, &quot;Bob&quot;, &quot;Zach&quot;) names_1 &lt;- sort(names, decreasing = TRUE) # order in reverse alphabetical order names_1 ## [1] &quot;Zach&quot; &quot;Charlie&quot; &quot;Bob&quot; &quot;Alice&quot; order() This function returns the indices that would sort the vectors. For instance lets sort the vector v = c(43, 82, 11, 73, 34) in an ascending order(from smallest to the largest). The smallest number in this case is 11, therefore, the order() function will return 1 while 82 is the largest(5th smallest) number in this case, it will be returned as 5. v = c(43, 82, 11, 73, 34) order(v, decreasing = FALSE) ## [1] 3 5 1 4 2 &lt;&lt;&lt;&lt;Add two more examples&gt;&gt;&gt;&gt; rank() Returns of the rank of the element in a vector, list. The smallest element is ranked as 1(in this case its 11) while largest element is ranked last(82 is ranked 5 here) v = c(43, 82, 11, 73, 34) rank(v, ties.method = &quot;average&quot;, na.last = TRUE) ## [1] 3 5 1 4 2 rev() This function simply reverse the order of elements. The first element in a vector will be last while the last one will be first. v = c(43, 82, 11, 73, 34) rev(v) ## [1] 34 73 11 82 43 Sorting Data Frames A data frame can be sorted in descending/ascending order of a certain column. For instance, we will sort the titanic data set in the order of age in ascending order. titanic_by_age &lt;- titanic[order(titanic$Age), ] head(titanic_by_age) ## PassengerId Survived Pclass Name Sex Age ## 804 804 1 3 Thomas, Master. Assad Alexander male 0.42 ## 756 756 1 2 Hamalainen, Master. Viljo male 0.67 ## 470 470 1 3 Baclini, Miss. Helene Barbara female 0.75 ## 645 645 1 3 Baclini, Miss. Eugenie female 0.75 ## 79 79 1 2 Caldwell, Master. Alden Gates male 0.83 ## 832 832 1 2 Richards, Master. George Sibley male 0.83 ## SibSp Parch Ticket Fare Cabin Embarked ## 804 0 1 2625 8.5167 C ## 756 1 1 250649 14.5000 S ## 470 2 1 2666 19.2583 C ## 645 2 1 2666 19.2583 C ## 79 0 2 248738 29.0000 S ## 832 1 1 29106 18.7500 S Sorting the titanic data by age in descending order, - will be added infront of argument titanic$Age to be -titanic$Age titanic_by_age &lt;- titanic[order(-titanic$Age), ] # note the - sign head(titanic_by_age) ## PassengerId Survived Pclass Name Sex Age ## 631 631 1 1 Barkworth, Mr. Algernon Henry Wilson male 80.0 ## 852 852 0 3 Svensson, Mr. Johan male 74.0 ## 97 97 0 1 Goldschmidt, Mr. George B male 71.0 ## 494 494 0 1 Artagaveytia, Mr. Ramon male 71.0 ## 117 117 0 3 Connors, Mr. Patrick male 70.5 ## 673 673 0 2 Mitchell, Mr. Henry Michael male 70.0 ## SibSp Parch Ticket Fare Cabin Embarked ## 631 0 0 27042 30.0000 A23 S ## 852 0 0 347060 7.7750 S ## 97 0 0 PC 17754 34.6542 A5 C ## 494 0 0 PC 17609 49.5042 C ## 117 0 0 370369 7.7500 Q ## 673 0 0 C.A. 24580 10.5000 S Also, dataframes can be sorted based by multiple columns. Lets sort the titanic data set by Passenger class (Pclass) in ascending order and by age in descending order at once. # Pclass in ascending order, Age in descending order titanic_sorted_by_class_and_age &lt;- titanic[order(titanic$Pclass, -titanic$Age), ] head(titanic_sorted_by_class_and_age) ## PassengerId Survived Pclass Name Sex Age ## 631 631 1 1 Barkworth, Mr. Algernon Henry Wilson male 80 ## 97 97 0 1 Goldschmidt, Mr. George B male 71 ## 494 494 0 1 Artagaveytia, Mr. Ramon male 71 ## 746 746 0 1 Crosby, Capt. Edward Gifford male 70 ## 55 55 0 1 Ostby, Mr. Engelhart Cornelius male 65 ## 457 457 0 1 Millet, Mr. Francis Davis male 65 ## SibSp Parch Ticket Fare Cabin Embarked ## 631 0 0 27042 30.0000 A23 S ## 97 0 0 PC 17754 34.6542 A5 C ## 494 0 0 PC 17609 49.5042 C ## 746 1 1 WE/P 5735 71.0000 B22 S ## 55 0 1 113509 61.9792 B30 C ## 457 0 0 13509 26.5500 E38 S 4.1.4 Basic Data Cleaning Data Cleaning is the process of fixing, removing incorrect, incomplete or otherwise problematic data from a data set. This is a crucial step in data analysis as it leads to more reliable analyses and insights. Here some data cleaning techniques used; Handling Missing Data The null values are identified by is.na() function. If there exists null values, they are removed by na.omit() function. The null values can also be replaced by appropriate substitutes such as the mean, median, zero value or a placeholder, this is referred to as imputation. Lets create a vector myvector will null values, identify the null values, remove/impute them. # Create a vector that has missing values my_vector &lt;- c(12, 43, NA, 32, 65, 11, NA, NA, 34, 98, 57) # NA is the missing value # Identify existence of the null values is.na(my_vector) ## [1] FALSE FALSE TRUE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE # Count the null values sum(is.na(my_vector)) ## [1] 3 # remove null values clean_vector &lt;- na.omit(my_vector) clean_vector ## [1] 12 43 32 65 11 34 98 57 ## attr(,&quot;na.action&quot;) ## [1] 3 7 8 ## attr(,&quot;class&quot;) ## [1] &quot;omit&quot; # impute missing values my_vector[is.na(my_vector)] &lt;- mean(my_vector, na.rm = TRUE) my_vector ## [1] 12 43 44 32 65 11 44 44 34 98 57 &lt;- Add more ways to remove null values -&gt; https://sparkbyexamples.com/r-programming/remove-na-from-vector-in-r/#:~:text=In%20R%2C%20NA%20denotes%20’Missing,NA%20values%20from%20a%20vector. Removing Duplicates In a raw data set there may exist some duplicated entries/records/rows that will give false results in data analysis thereby leading to poor insights and decision-making. The duplicates are identified by duplicated() function. If there exists any duplicates, they are removed by subsetting or calling unique() function. Lets create a data frame with duplicate values and remove them # Creating a simple data frame data &lt;- data.frame( Position = c(1, 2, 3, 4, 5, 3), # Notice the duplicate position Name = c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Charlie&quot;, &quot;David&quot;, &quot;Eva&quot;, &quot;Charlie&quot;), Age = c(25, 30, NA, 40, 29, NA), # NA represents null values Score = c(85, 90, 88, NA, 92, 88) # NA represents null values ) # Position 3 is duplicated # Display the data frame print(data) ## Position Name Age Score ## 1 1 Alice 25 85 ## 2 2 Bob 30 90 ## 3 3 Charlie NA 88 ## 4 4 David 40 NA ## 5 5 Eva 29 92 ## 6 3 Charlie NA 88 print(&quot;CLEAN DATA&quot;) ## [1] &quot;CLEAN DATA&quot; # Remove the duplicate row clean_data &lt;- unique(data) clean_data ## Position Name Age Score ## 1 1 Alice 25 85 ## 2 2 Bob 30 90 ## 3 3 Charlie NA 88 ## 4 4 David 40 NA ## 5 5 Eva 29 92 Also the duplicated rows can be removed by clean_data2 &lt;- data[!duplicated(data), ] clean_data2 ## Position Name Age Score ## 1 1 Alice 25 85 ## 2 2 Bob 30 90 ## 3 3 Charlie NA 88 ## 4 4 David 40 NA ## 5 5 Eva 29 92 Handling Outliers Outliers are extreme values that differ from most other data points in a data set. hey can be detected by identifying the upper bound and lower bound using boxplots. They are removed by; clean_data &lt;- raw_data[raw_data$column &lt; upper_bound &amp; raw_data$column &gt; lower_bound, ] Standardizing Data There are numerous ways that data can be standardized such ensuring a consistent date format across the data set and correcting case. Lets create a vector with different date formats and make it consistent # Creating a vector with different date formats date_vector &lt;- c(&quot;2023-08-01&quot;, &quot;01/08/2023&quot;, &quot;August 1, 2023&quot;, &quot;20230801&quot;, &quot;08-01-2023&quot;) # Converting the date_vector to a consistent format clean_date_vector &lt;- as.Date(date_vector, format=&quot;%Y-%m-%d&quot;) # Display the clean date vector print(clean_date_vector) ## [1] &quot;2023-08-01&quot; NA NA NA &quot;8-01-20&quot; The lubridate package can do it better # Load necessary library library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union # Correcting each date format using lubridate functions clean_date_vector &lt;- c( as.Date(date_vector[1], format=&quot;%Y-%m-%d&quot;), # &quot;2023-08-01&quot; as.Date(date_vector[2], format=&quot;%d/%m/%Y&quot;), # &quot;01/08/2023&quot; as.Date(date_vector[3], format=&quot;%B %d, %Y&quot;), # &quot;August 1, 2023&quot; as.Date(date_vector[4], format=&quot;%Y%m%d&quot;), # &quot;20230801&quot; as.Date(date_vector[5], format=&quot;%m-%d-%Y&quot;) # &quot;08-01-2023&quot; ) # Display the clean date vector print(clean_date_vector) ## [1] &quot;2023-08-01&quot; &quot;2023-08-01&quot; NA &quot;2023-08-01&quot; &quot;2023-08-01&quot; 4.1.5 Hands-on Exercises 4.2 Data Manipulation with Dplyr 4.2.1 Introduction to Dplyr package Dplyr is a package designed for data manipulation equipped with a set of intuitive functions to perform tasks like filtering rows, selecting columns, rearranging data and summarizing information. The package is part of a larger library, tidyverse. The tidyverse package is a package designed for data science that share an underlying design philosophy, grammar and data structures. The packages within the tidyverse are widely used for data manipulation, exploration, and visualization in R. Here are some of the core packages in tidyverse; ggplot2 dplyr tidyr readr purrr tibble The tidyverse package is installed by install.packages(&quot;tidyverse&quot;) To invoke the package into the system, the below command is invoked library(tidyverse) ## ── Attaching core tidyverse packages ────── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ purrr 1.0.2 ✔ tidyr 1.3.1 ## ── Conflicts ───── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors In this course, we will discuss on dplyr since it is an essential tool in data analysis. If you want to use dplyr alone then it can be installed by; install.packages(&quot;dplyr&quot;) To load the library into the system; library(dplyr) 4.2.2 Key Functions in dplyr There are some functions that are use by data scientist when working with dplyr, they are referred to as dplyr verbs. To explain these verbs better, we will use an example data set to explain. A good example is the famous iris data set, it is always used by beginners in data science. The data set contains measurements of various characteristics of iris flowers. These characteristics include sepal length, sepal width, petal length, and petal width. There are three species of iris flowers in the data set: setosa, versicolor, and virginica. The data will be invoked to R before assessment and wrangling; Lets load the iris data and explore the first few records. data(&quot;iris&quot;) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa 4.2.3 select This dplyr verb is used when selecting or dropping specific columns. In this lesson we will find the iris column names and select two of them using select. data(iris) # Find the column names colnames(iris) ## [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot; &quot;Petal.Length&quot; &quot;Petal.Width&quot; &quot;Species&quot; Remember the data frame to work on need to be specified in the arguments such that selected_data = select(data_frame, col1, col2, col3) Therefore, we will select the columns; Species, Petal length and petal width. # Load the required libraries library(dplyr) # Load the iris data data(iris) selected_iris_data = select(iris, Petal.Length, Petal.Width, Species) # view the first few rows of the selected data head(selected_iris_data) ## Petal.Length Petal.Width Species ## 1 1.4 0.2 setosa ## 2 1.4 0.2 setosa ## 3 1.3 0.2 setosa ## 4 1.5 0.2 setosa ## 5 1.4 0.2 setosa ## 6 1.7 0.4 setosa The three selected columns are displayed in the data frame above. Specific columns can be dropped by putting - before the column name as # Drop specified columns remaining_data = select(data_frame, -col1_to_drop, -col2_to_drop) In this lesson, we will drop petal length, petal width and Species columns; # Load the required libraries library(dplyr) # Load the iris data data(iris) # Drop some columns remaining_iris_data = select(iris, -Petal.Length, -Petal.Width, -Species) # view the first few rows of the selected data head(remaining_iris_data) ## Sepal.Length Sepal.Width ## 1 5.1 3.5 ## 2 4.9 3.0 ## 3 4.7 3.2 ## 4 4.6 3.1 ## 5 5.0 3.6 ## 6 5.4 3.9 Activity You will be required to use the car_sales data set from https://raw.githubusercontent.com/insaid2018/Term-1/master/Data/Projects/car_sales.csv. Read the data using read.csv and select the car, price, body, mileage, engV, engType, year, model. Save the data frame from the selected columns as selected_cars_df. Show the first few rows of the selected_cars_df. # Load the dplyr library # CODE HERE # Read the data # CODE HERE # select the required columns # CODE HERE # Show the first few rows of the data frame # CODE HERE 4.2.4 filter Is a verb/function from dplyr used to filter records in a data frame based on a specific condition. It allows the analyst to retrieve the records he/she is interested in and work easier with the subset. With filter(), the data frame and the condion are passed as a arguments; # Filtering rows where a certain column meets a condition filtered_data = filter(data_frame, column_name &gt; 5 # This is the condition) Lets select the species ‘setosa’ from the iris data set # Load the required libraries library(dplyr) # Load the iris data data(iris) # Filter to select Setosa setosa_iris = filter(iris, # the data frame Species == &quot;setosa&quot; # the condition ) # First few records of setosa data head(setosa_iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Records with sepal width of more than 3.0 can be filtered. Here is how we achieve such a subset # Load the required libraries library(dplyr) # Load the iris data data(iris) # Filtered to select records with more than 3.0 sepal width wide_sepal_iris = filter(iris, #the data frame Sepal.Width&gt;3.0 # the condition ) head(wide_sepal_iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.7 3.2 1.3 0.2 setosa ## 3 4.6 3.1 1.5 0.2 setosa ## 4 5.0 3.6 1.4 0.2 setosa ## 5 5.4 3.9 1.7 0.4 setosa ## 6 4.6 3.4 1.4 0.3 setosa Activity With the car_sales data set that you used above, use filter() function to get the cars that were sold from the year 2008 to present and name them latest_car_sales. Count the number of observations made and show the first few rows. # Load the dplyr library # CODE HERE # Read the data # CODE HERE # Filter to find cars sold from 2008 # CODE HERE # Count the observations made. Use nrows function # CODE HERE # Show the first few rows # CODE HERE 4.2.5 arrange This is dplyr verb/function used for sorting rows by rearranging in a specific order. here is how to use arrange() function; arranged_data = arrange(data_frame, column_name) This allows the analyst to arrange the data in a default ascending order. To arrange in a descending order a desc() function is added as; # Note the additional desc function arranged_data = arrange(data_frame, desc(column_name)) Now lets order the iris data in an ascending order based on Petal length and view the first 6 records with the shortest petal. # Load the required libraries library(dplyr) # Load the iris data data(iris) # Sort the data by_petal_length = arrange(iris, # data frame Petal.Length # order by column ) # View the data head(by_petal_length) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 4.6 3.6 1.0 0.2 setosa ## 2 4.3 3.0 1.1 0.1 setosa ## 3 5.8 4.0 1.2 0.2 setosa ## 4 5.0 3.2 1.2 0.2 setosa ## 5 4.7 3.2 1.3 0.2 setosa ## 6 5.4 3.9 1.3 0.4 setosa Lets repeat the same process but now we order the data in a descending order. # Sort the data by_petal_length = arrange(iris, # data frame desc(Petal.Length) # order by column ) # View the data head(by_petal_length) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 7.7 2.6 6.9 2.3 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.8 6.7 2.0 virginica ## 4 7.6 3.0 6.6 2.1 virginica ## 5 7.9 3.8 6.4 2.0 virginica ## 6 7.3 2.9 6.3 1.8 virginica Activity Arrange the columns in the car_sales data set according to mileage in descending order. Show the last few rows # Load the dplyr library # CODE HERE # Read the data into a data frame # CODE HERE # Order according to mileage in descending order # CODE HERE # Show the last few rows of the data set # CODE HERE 4.2.6 mutate mutate() is a dplyr verb used to modifying the existing variables or creating new variables in a data set. In this case we can calculate the log off Sepal length in the iris data # Load the required libraries library(dplyr) # Load the iris data data(iris) # modify Sepal.Length new_iris = mutate(iris, Sepal.Length=log(Sepal.Length)) head(new_iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 1.629241 3.5 1.4 0.2 setosa ## 2 1.589235 3.0 1.4 0.2 setosa ## 3 1.547563 3.2 1.3 0.2 setosa ## 4 1.526056 3.1 1.5 0.2 setosa ## 5 1.609438 3.6 1.4 0.2 setosa ## 6 1.686399 3.9 1.7 0.4 setosa Additionally, we can create an entirely new variable by mutate(). In this case we will find the ratio between petal length and petal width. The new variable will be called “Petal.Length.Width.Ratio” # Load the required libraries library(dplyr) # Load the iris data data(iris) # Create a new column in the data set new_iris = mutate(iris, Petal.Length.Width.Ratio = Petal.Length/Petal.Width) head(new_iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## Petal.Length.Width.Ratio ## 1 7.00 ## 2 7.00 ## 3 6.50 ## 4 7.50 ## 5 7.00 ## 6 4.25 The “Petal.Length.Width.Ratio” is found by dividing the Petal.Length and the Petal.Width variables. Activity Using the car_sales data set, create a new column, \"distance_covered_km\", calculated from the mileage. Just multiply mileage with 1.609. Show the first few rows of the mutated data frame. # Load the dplyr library # CODE HERE # Read the data set # CODE HERE # Create new column &quot;distance_covered_km # CODE HERE # Show first few rows # CODE HERE 4.2.7 group_by The group_by() is a function used to group records in a data frame by one or more variables. It allows the analyst to create a group based on a certain criteria. Lets group the iris data based on the Species variable; # Load the required libraries library(dplyr) # Load the iris data data(iris) # Group the iris based on their Species iris_groups = group_by(iris, Species) head(iris_groups) ## # A tibble: 6 × 5 ## # Groups: Species [1] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa This groupings allow the analyst to retrieve insights at more base level and uncover more insights that could not have been possible when analyzing the entire data set Activity Use the car_sales data set provided before to work on this activity. Load the data and group the sales by model to get the sum of every quantitative feature/variable. Name the resultant data frame, car_sales_by_model. Display the resultant data frame. # Load the dplyr library # CODE HERE # Load the car sales data # CODE HERE # Group the sales by model # CODE HERE # Print out the dataframe # CODE HERE 4.2.8 Summarise To calculate summary statistics such as average, median and maximum the summarise() is used. This function collapses mutilple rows into a summary row. For instance calculating the mean Petal width; # Load the required libraries library(dplyr) # Load the iris data data(iris) # Calculate the mean petal width summarise(iris, mean_petal_width=mean(Petal.Width)) ## mean_petal_width ## 1 1.199333 To find the mean petal width for each iris species; - the iris data will be grouped by species - a mean value for each group will be calculated # Load the required libraries library(dplyr) # Load the iris data data(iris) # To find the mean petal width for each iris species; # - the iris data will be grouped by species # - a mean value for each group will be calculated grouped_iris = group_by(iris, Species) mean_petal_widths = summarise(grouped_iris, mean_value=mean(Petal.Width)) mean_petal_widths ## # A tibble: 3 × 2 ## Species mean_value ## &lt;fct&gt; &lt;dbl&gt; ## 1 setosa 0.246 ## 2 versicolor 1.33 ## 3 virginica 2.03 Activity You will be required to use the car_sales data set once again. Calculate the descriptive statistics using summarise() command. # Load the dplyr library # CODE HERE # Load the car sales data # CODE HERE # Calculate the summary statistics # CODE HERE 4.3 Chaining Chaining is the process of combining several operations together using the %&gt;% or forward pipe operator. The chained workflow succeeds each other until the whole process is done. To understand chaining, the mtcars(Motor Trend cars) data set will be used. Mtcars is also a well-known data set containing several attributes of 32 different cars from 1974. Here’s a brief explanation of the variables in the mtcars data set: mpg: Miles per gallon (fuel efficiency). cyl: Number of cylinders. disp: Displacement (cubic inches). hp: Horsepower. drat: Rear axle ratio. wt: Weight (in 1000 lbs). qsec: Quarter mile time (in seconds). vs: Engine type (0 = V-shaped, 1 = Straight). am: Transmission type (0 = Automatic, 1 = Manual). gear: Number of forward gears. carb: Number of carburetors. Lets start by loading the data into the program and view its first few records; data(mtcars) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 Lets select 6 most important columns in this analysis # Load the library library(dplyr) # Load the data data(mtcars) # Lets `select` 6 most important columns in this analysis cars1 = mtcars %&gt;% select(mpg, cyl, disp, hp, qsec, am) head(cars1) ## mpg cyl disp hp qsec am ## Mazda RX4 21.0 6 160 110 16.46 1 ## Mazda RX4 Wag 21.0 6 160 110 17.02 1 ## Datsun 710 22.8 4 108 93 18.61 1 ## Hornet 4 Drive 21.4 6 258 110 19.44 0 ## Hornet Sportabout 18.7 8 360 175 17.02 0 ## Valiant 18.1 6 225 105 20.22 0 Lets now filter to find vehicles with an automatic transmission type. The filter verb will be chained to select verb with %&gt;%. # Load the library library(dplyr) # Load the data data(mtcars) # Selct and filter chained together cars2 = mtcars %&gt;%select(mpg, cyl, disp, hp, qsec, am) %&gt;% filter(am==0) head(cars2) ## mpg cyl disp hp qsec am ## Hornet 4 Drive 21.4 6 258.0 110 19.44 0 ## Hornet Sportabout 18.7 8 360.0 175 17.02 0 ## Valiant 18.1 6 225.0 105 20.22 0 ## Duster 360 14.3 8 360.0 245 15.84 0 ## Merc 240D 24.4 4 146.7 62 20.00 0 ## Merc 230 22.8 4 140.8 95 22.90 0 All these vehicles are of automatic transmission type, lets rank them according to the horsepower in descending order. # Load the library library(dplyr) # Load the data data(mtcars) # Select, filter and arrange chained together cars3= mtcars %&gt;%select(mpg, cyl, disp, hp, qsec, am, wt) %&gt;% filter(am==0) %&gt;% arrange(desc(hp)) head(cars3) ## mpg cyl disp hp qsec am wt ## Duster 360 14.3 8 360.0 245 15.84 0 3.570 ## Camaro Z28 13.3 8 350.0 245 15.41 0 3.840 ## Chrysler Imperial 14.7 8 440.0 230 17.42 0 5.345 ## Lincoln Continental 10.4 8 460.0 215 17.82 0 5.424 ## Cadillac Fleetwood 10.4 8 472.0 205 17.98 0 5.250 ## Merc 450SE 16.4 8 275.8 180 17.40 0 4.070 A new column of weight in 1000kgs (wt_1000kgs) can be created by diving weight in 1000lbs by 2.20462. mutate verb will be chained also. # Load the library library(dplyr) # Load the data data(mtcars) # Multiple chains cars4= mtcars %&gt;%select(mpg, cyl, disp, hp, qsec, am, wt) %&gt;% filter(am==0) %&gt;% arrange(desc(hp)) %&gt;% mutate(wt_1000kgs=wt/2.20462) head(cars4) ## mpg cyl disp hp qsec am wt wt_1000kgs ## Duster 360 14.3 8 360.0 245 15.84 0 3.570 1.619327 ## Camaro Z28 13.3 8 350.0 245 15.41 0 3.840 1.741797 ## Chrysler Imperial 14.7 8 440.0 230 17.42 0 5.345 2.424454 ## Lincoln Continental 10.4 8 460.0 215 17.82 0 5.424 2.460288 ## Cadillac Fleetwood 10.4 8 472.0 205 17.98 0 5.250 2.381363 ## Merc 450SE 16.4 8 275.8 180 17.40 0 4.070 1.846123 The above process has explained how chained works in dplyr. Many functions/processed can be chained together to manipulate data to the desired output. The next section will apply chaining to biology and be used to answer a few questions that will cement your understanding in R as a biologist. 4.3.1 Hands-on Exercises "],["data-visualization.html", "Chapter 5 Data Visualization 5.1 Basic Data Visualization 5.2 Advanced Data Visualization", " Chapter 5 Data Visualization 5.1 Basic Data Visualization 5.1.1 Introduction to ggplot2 This is package designed for data visualization. It provides a powerful and flexible framework for creating complex and aesthetically pleasing visualizations, allowing users to layer various components such as axes, scales, colors, and geoms to create detailed and customizable plots. The package is said that it implements the principle of “Grammar of Graphics”. The “Grammar of Graphics” is a conceptual framework for creating graphs by Leland Wilkinson. The process of creating graphs is broken into fundamental components. This allows structure and flexible approach in data visualization. The plots are constructed by a layered approach by implementing these concepts step by step; data, aesthetics(aes), geometrics(geoms), statistical transformations (stats), scales, cordinates and facets. The package is also under the tidyverse package but can be installed by install.packages(&quot;ggplot2&quot;) Once the package is installed, it can be loaded by library(ggplot2) There are 5 key steps in plotting in ggplot; 1.The Setup - Read the data set, define x and y axis The Labels - Title, X and Y axis labels The Theme - Default, Black and White, colored etc. The Facets - Individual Graphs for each group in data with exactly same range The Layers or geoms - The actual plot type - e.g Bar plot, Box plot, Violin plot etc. Here is an example of a layered approach in creating charts by applying the “Grammar of Graphics”. library(ggplot2) # Sample data df &lt;- data.frame( x = rnorm(100), y = rnorm(100), category = sample(c(&quot;A&quot;, &quot;B&quot;), 100, replace = TRUE) ) # Creating a scatter plot ggplot(df, # data aes(x = x, y = y, color = category)) + #aesthetics geom_point() + #geometrics labs(title = &quot;Scatter Plot Example&quot;, x = &quot;X-Axis&quot;, y = &quot;Y-Axis&quot;) + theme_minimal() 5.1.1.1 Creating Basic Plots Scatter Plots Scatter plot is used to show a numerical relationship between two or more variables for instance height versus weight of footballers. It is also used to detect correlation, the increase in one variable can lead to increase/decrease of another variable. Furthermore scatter plots are used to detect outliers, values that appear out of the general patterns of other data points is said to be an outlier in this case. However, scatter plots is not suitable when working with categorical data especially when only two variables are to be analyzed. Lets create a basic scatter plot to compare height and weight;- #Prepare a Sample data df &lt;- data.frame( height = c(150, 160, 170, 180, 190), weight = c(50, 60, 70, 80, 90) ) # Creating a basic scatter plot ggplot(df, # data aes(x = height, y = weight)) + # aesthetics geom_point() To make the chart more informative, titles and labels are added. # Creating a basic scatter plot ggplot(df, # data aes(x = height, y = weight)) + # aesthetics geom_point() + labs(title = &quot;Height vs. Weight&quot;, x = &quot;Height (cm)&quot;, y = &quot;Weight (kg)&quot;) + theme_minimal() Lets explain the chart step by step;- ggplot(df, aes(x = height, y = weight)): Initializes the ggplot object, specifying the data frame (df) and mapping the height variable to the x-axis and the weight variable to the y-axis using the aes() function. geom_point(): Creates the scatter plots by adding dots to the chart labs(): Adds the title and the axis labels to the chart. theme_minimal(): Applies a minimal theme to the plot for a minimalist and clean appearance. &lt;-Practical exercise: Creating scatter plots for different datasets-&gt; Bar Charts Bar charts are used to represent both categorical and numeric data in form of rectangular bars. The length/height of each category represents its numeric value. It may corresponds to either length, count, age or any other numerical value. Bar charts are used when;- Comparing categorical data Visualizing summarized data for instance aggregated sum, average or any other summary statistics. Showing frequency or count for instance representing the number of products sold per each category. Ranking data. Bar charts can effectively represents ranks especially in descending/ascending order for instance ranking the life expectancy of different countries. Other type of complex bar charts like stacked bar charts can be used to compare part-to-whole relationships. There are many more uses of bar charts however there are some use cases where bar charts are not preferred like when working with continuous data, scatter and line charts are more befitting. Also, bar charts are not appropriate where data has too many categories, heatmaps will do better. To create a simple bar chart using ggplot2, we use geom_bar to define thats its a bar chart. # Sample data df &lt;- data.frame( category = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;), value = c(23, 17, 35, 10) ) ## The data set above will be used to create a bar chart # Creating a bar chart ggplot(df, aes(x = category, y = value)) + geom_bar(stat = &quot;identity&quot;) + labs(title = &quot;Value by Category&quot;, x = &quot;Category&quot;, y = &quot;Value&quot;) + theme_minimal() &lt;-Practical exercise: Creating bar charts for categorical data.-&gt; Histograms 5.2 Advanced Data Visualization "],["explanatory-data-analysis.html", "Chapter 6 Explanatory Data Analysis 6.1 Introduction to EDA", " Chapter 6 Explanatory Data Analysis 6.1 Introduction to EDA Exploratory Data Analysis (EDA) is a critical process in the data analysis workflow. It involves examining and visualizing a dataset to uncover patterns, spot anomalies, test hypotheses, and check assumptions using summary statistics and graphical representations. EDA provides a solid understanding of the data and lays the foundation for more advanced statistical analyses or machine learning models. The key objectives of EDA are;- Understand and familiarize the data structure. Detect outliers and anomalies. Identify patterns and trends. Check and verify assumptions, etc. By performing EDA thoroughly, the groundwork is laid for more accurate results, ultimately provides insights that lead to better decision-making. EDA also guides to better model-selection. Here are the common techniques involved in EDA;- Summary Statistics: The analysts compute the summary statistics like mean, median, mode and standard deviation to find the spread and central tendency in the data. Data Visualization: Charts and graphs are drawn to provide a visual interpretation of the data set. Data Cleaning and Preparation: Data manipulation and pre-processing is done to reduce the risk of misinterpretation. There are more EDA techniques like univariate, bivariate and multivariate analysis, and inferential statistics. 6.1.1 EDA in practice 6.1.1.1 Choosing a data set 6.1.1.2 Conducting EDA 6.1.1.3 Present Findings "],["statistical-analysis.html", "Chapter 7 Statistical Analysis 7.1 Basic Statistical Concepts 7.2 Correlation and Regression Analysis 7.3 Advanced Statistical Methods 7.4 Datasets", " Chapter 7 Statistical Analysis 7.1 Basic Statistical Concepts 7.1.1 Introduction to Descriptive Statistics Mean, Median and Mode Mean is the sum of all values divided by the number of values in the set. It also referred to as average. Median is the middle value when values in a data set is ordered/lined up in ascending/descending order. Mode is the number that occurs most in the data set. Simply, the most frequent value in the data set. All these, are measures of central tendency. Central tendency identifies the center or typical value of a data set. Measuring central tendency summarizes the data by identifying skewness, distribution and how the data is robust to outliers. Business calculate the central tendencies like average sales, median customer age to make informed decision-making. Below is the formula to calculate mean. where xi represents each value in the data set, and n is the number of values. Lets calculate mean of the vector ages with the values 12, 58, 27, 33, 31, 27, 37 manually with the steps below; # Add the values together total_age = 12 + 58 + 27 + 33 + 31 + 27 + 37 total_age # is 225 number_of_values = 7 # there are 7 values mean age = total_age/number_of_values mean_age # is 32.14 The average age is 32.14. To calculate the median of the vector ages, the ages are arranged in descending/ascending order and the middle one is selected. In this case we will line them up in ascending order # Line the ages up in ascending order 12, 27, 27, 31, 33, 37, 58 # There are 7 ages, the fourth one from either side is the median value # The median age is 31 To find mode, you just find the value that appears the most, for the values 12, 27, 27 , 31, 33, 37, 58, age 27 appears twice while these other ages appear once. The value 27 is therefore the mode. Mean, median and mode can also be calculated using Base R using the functions mean(), median() and mode() where the vector ages is the argument. # Create vector ages ages = c(12, 58, 27, 33, 31, 27, 37) # Average/mean mean(ages) ## [1] 32.14286 # Median median(ages) ## [1] 31 # Mode mode(ages) ## [1] &quot;numeric&quot; &lt;-Add a practical exercise-&gt; Variance and Standard deviation Variance is statistical measure of dispersion that defines how spread the data points are in a data set in relation to the mean of the data set. Standard deviation is the measure of how data is clustered around the mean. It is simply defined to as the square root of variance. Variance and standard deviation can be calculated in R environment using var() and sd() functions respectively. Lets create a vector of weights of the athletes in kilograms and calculate the variance and standard deviation. # Sample vector athlete_weights = c(55, 76, 52, 68, 71, 63, 58, 52, 85, 96) # Calculate variance var(athlete_weights) ## [1] 216.7111 # Calculate standard deviation sd(athlete_weights) ## [1] 14.72111 &lt;-Add a practical exercise-&gt; Range and Interquartile Range Range is the difference between the maximum and minimum values in the data set. This defines the spread and dispersion of a data set. Below is the formula for Range: Range = Maximum Value - Minimum Value Lets use the weights vector above to calculate the range; weights = 55, 76, 52, 68, 71, 63, 58, 52, 85, 96 maximum_weight = 96 minimum_weight = 52 Range = maximum_weight - minimum_weight = 44 Range is essential in data analysis as it gives a quick sense of variability in the data set, however it vulnerable to outliers since it gives importance to the maximum and minimum values even if they are extreme. Interquartile Range(IQR) is the difference between the first quartile (Q1) and third quartile(Q3) value. First Quartile is the median of the lower half of the data while Thrid quartile is the median of the upper of the data set. Therefore IQR = Q3 - Q1 Lets calculate the IQR of the vector weights step by step;- Define the data weights and arrange the data in ascending order. weights = 52, 52, 55, 58, 63, 68, 71, 76, 85, 96. Determine the first quartile (Q1). Select the lower half(first five values) of the data and find their median which is the first quartile (Q1) lower_half = 52, 52, 55, 58, 63 Q1 = 55 Determine the third quartile (Q3). Select the upper half(last five values) and find their median which is the third quartile. upper_half = 68, 71, 76, 85, 96 Q3 = 76 Calculate the Interquartile Range (IQR) by finding the difference between Q1 and Q3. IQR = Q3 - Q1 = 76 - 55 = 21 The IQR for the weights data set is 21. Range and IQR can be calculated in R environment using the range() and IQR() function respectively. However function range returns the maximum and the minmum values in the dataset. # Sample vector athlete_weights = c(55, 76, 52, 68, 71, 63, 58, 52, 85, 96) # RANGE range(athlete_weights) # returns maximum and minimum values ## [1] 52 96 diff(range(athlete_weights)) # calculate the range value ## [1] 44 # INTER QUARTILE RANGE (IQR)http://127.0.0.1:38237/rmd_output/1/basic-data-types-and-structures.html IQR(athlete_weights) ## [1] 19 &lt;-Add a practical exercise-&gt; 7.1.2 Visualization of Descriptive Statistics 7.2 Correlation and Regression Analysis 7.2.1 Introduction to Correlation Pearson and Spearman Correlation Correlation is the relationship between two variables. It can also defined to as the statistic measure to the degree to which two variables move in relation to each other. There are two types of correlation in statistics;- pearson and spearman correlations. They differ in their calculation methods, assumptions and type of relationships they are suited for. Pearson correlation measures the linear relationship between two variables with the assumptions that there is a linear relationship between the variables and the data is normally distributed. Contrarily, Spearman correlation measures the monotonic relationship(whether there is a consistent positive or negative change ) between two variables. The data to be analyzed, don’t need to be normally distributed, it can be ordinal with the variables having a non-linear relationship. Lets take two variables, X and Y, Pearson correlation is calculated by dividing the covariance of X and Y with their product of standard deviation. Below is its formula; r is the pearson correlation and it can range from -1 to +1. Spearman correlation is calculated by ranking data points, then applying Pearson correlation formula. Below is the formula of spearman correlation; where; d is the difference between the ranks of corresponding variables n is the number of observations r is the pearson correlation Spearman correlation is insensitive with outliers because it uses ranks other than outliers. &lt;-Add a practical exercise-&gt; Visualizing Correlation Demonstration of scatter plots to visualize the relationship between two variables. Introduction to correlation heatmaps using ggcorrplot or corrplot. Practical exercise: Create scatter plots and correlation heatmaps for a dataset. 7.2.2 Introduction to Regression Analysis Regression is a statistical method used to measure the strength and relationship of a target(dependent) with one or more independent variables. Correlation is very vital in determining regression. Linear regression is the most technique of regression, there are some more advanced forms of regression. Simple Linear Regression This type of regression is used to estimate the relation of one independent variable with the target variable. For instance the relationship between age and height of children. relationship between weight and BMI of athletes, relationship between rainfall and soil erosion. When creating a simple linear regression model, a line is fitted a line to the observed data. Simple linear regression is modeled by this equation; y = c + BX + e Where;- y is the target variable X is the independent variable B is the slope.gradient(change in y for one-unit change in X) c is the y-intercept(Value of target variable when independent variable is zero) e is the error/noise. variation in y but not as a resultant explained by X The goal of simple of linear regression it to have the best fitting line that with the equation y = BX + c. Base R has a method of fitting a linear regression and finding the best fit line using lm() function. lm() stands for “linear model”. Lets create a simple linear regression model to a hypothetical data set where height of athletes is predicted based on weight. # Create a sample dataset height &lt;- c(150, 160, 170, 180, 190) # Independent variable (x) weight &lt;- c(65, 70, 75, 80, 85) # Dependent variable (y) # Combine into a data frame data &lt;- data.frame(height, weight) print(data) ## height weight ## 1 150 65 ## 2 160 70 ## 3 170 75 ## 4 180 80 ## 5 190 85 # Fit the linear model lin_reg &lt;- lm(weight ~ height, data = data) # View the summary of the model summary(lin_reg) ## Warning in summary.lm(lin_reg): essentially perfect fit: summary may be ## unreliable ## ## Call: ## lm(formula = weight ~ height, data = data) ## ## Residuals: ## 1 2 3 4 5 ## 1.335e-14 -1.367e-14 -6.097e-15 -1.891e-16 6.607e-15 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.000e+01 6.575e-14 -1.521e+14 &lt;2e-16 *** ## height 5.000e-01 3.854e-16 1.297e+15 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.219e-14 on 3 degrees of freedom ## Multiple R-squared: 1, Adjusted R-squared: 1 ## F-statistic: 1.683e+30 on 1 and 3 DF, p-value: &lt; 2.2e-16 Coefficients, the value B and c represent the intercept and the gradient(slope) in the equation. The R- Squared value indicates how well the independent variable explains the dependent variable. The closer the R-square value to 1 the better the fit. Finally, the p-value is associated with the gradient and tells the statistician whether the relationship between the variables is statistically significant. &lt;–Add a practical exercise-&gt; Multiple Linear Regression Unlike simple linear regression, multiple linear regression describes the linear relationship between two or more independent variables with one target(dependent) variable. The objective of multiple linear regression is to;- Find the strength of the relationship between two or more independent variables with the target variables. Find the value of the target variable at a certain value of the independent variable. When working on a multiple linear regression it is assumed that; the variance is homogeneous such that the prediction error does not change significantly across the predictor(independent) variables. It is also assumed, observations were independent and there was no hidden relationships among the variables when collecting the data. Additionally, the collected data follows a normal distribution and the independent variables have a linear relationship(linearity) with the dependent variable, therefore, the line of best fit through the data points is straight and not curved. Multiple linear regression is modeled by;- where;- \\(y\\) is the predicted value of the target variable. \\(\\beta_0\\) is the y-intercept. Value of y when all other parameters are zero. \\(\\beta_1X_1\\): \\(\\beta_1\\) is the regression coefficient of the first independent variable while \\(X_1\\) is the independent variable value. \\(\\cdots\\) do the same for however the number of independent variables are present. \\(\\beta_nX_n\\): the regression coefficient of the last independent variable. \\(\\epsilon\\) is the model error(variation not explained by the independent variables) The Multiple linear regression model calculates three things to find the best fit line for each independent variable;- The regression coefficient \\(\\beta_iX_i\\) that will minimize the overall error rate(model error). The associated p-value. If the relationship between the independent variable is statistically significant. The t-statistic of the model. T-statistic is the ratio of the difference in a number’s estimated value from its assumed value to its standard error. Lets create a multiple linear regression from a hypothetical data using base R. # Create a sample dataset height &lt;- c(150, 160, 170, 180, 190) # Independent variable 1 (x1) age &lt;- c(25, 30, 35, 40, 45) # Independent variable 2 (x2) weight &lt;- c(65, 70, 75, 80, 85) # Dependent variable (y) # Combine into a data frame data &lt;- data.frame(height, age, weight) data ## height age weight ## 1 150 25 65 ## 2 160 30 70 ## 3 170 35 75 ## 4 180 40 80 ## 5 190 45 85 # Fit the linear model with multiple predictors model &lt;- lm(weight ~ height + age, data = data) # View the summary of the model summary(model) ## Warning in summary.lm(model): essentially perfect fit: summary may be ## unreliable ## ## Call: ## lm(formula = weight ~ height + age, data = data) ## ## Residuals: ## 1 2 3 4 5 ## 1.335e-14 -1.367e-14 -6.097e-15 -1.891e-16 6.607e-15 ## ## Coefficients: (1 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.000e+01 6.575e-14 -1.521e+14 &lt;2e-16 *** ## height 5.000e-01 3.854e-16 1.297e+15 &lt;2e-16 *** ## age NA NA NA NA ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.219e-14 on 3 degrees of freedom ## Multiple R-squared: 1, Adjusted R-squared: 1 ## F-statistic: 1.683e+30 on 1 and 3 DF, p-value: &lt; 2.2e-16 &lt;-Interpret the results-&gt; &lt;-Add a practical exercise-&gt; Hands-on Exercises Participants conduct correlation analysis and fit regression models on provided datasets. Interpretation and discussion of the statistical models and their implications. 7.3 Advanced Statistical Methods 7.3.1 Introduction to Hypothesis Testing Concept of Hypothesis Testing Hypothesis testing is a type of statistical analysis that is used to make assumptions of a population based on a sample of data. It is particularly used to find the relationship between two variables(populations). A real life example of hypothesis testing is that a teacher may assume that 60% of the students come from a middle-class family. There are two types of hypothesis; Null hypothesis(\\(H_0\\)) Alternate hypothesis (\\(H_1\\) or \\(H_a\\)) Null hypothesis is states that there is no effect or no difference(\\(\\mu = 0\\)). For instance there is no effect of standards of living to college admissions. Alternate hypothesis is the opposite and contradicts the null hypothesis. It provide evidence for what the statistician is trying to find(\\(\\mu \\neq 0\\)). In this case, the standards of living have an effect on college admissions. The important aspects before conducting hypothesis testing are;- Significance level. It is the probability of rejecting the null hypothesis when it is actually true. P-Value is the probability of obtaining a test statistic at least as extreme as the one observed, given the null hypothesis is true. Most hypothesis testing projects are set at 0.05. Less than 0.05(or the set value) indicates the null the test is statistically significant and the null hypothesis should be rejected. Otherwise, the test is statistically insignificant and the null hypothesis is not rejected. Test statistic also called T-statistic is a standardized value calcluated during a hypothesis test. It cab z-test or a t-test. -Decision rule is based on the calculated p-value and the significant level. In a hypothesis test where the significant and the p-value is 0.03444 the null hypothesis is not rejected. Now that you are familiar with the hypothesis testing aspects, take the following steps to perform hypothesis testing;- Formulating the hypothesis by defining the null and alternate hypothesis. Collect and analyze the data. Choose a significant level(\\(a\\)) and calculate the p-value. Make a decision by comparing the p-value to the significant level. Conclude your analysis results. T-tests One-Sample t-test -Two-Sample t-test 7.4 Datasets tweets Dataset from the rtweet Package “Credit Card Fraud” dataset ifrom R package creditcard The “Groceries” from the R package comes arules “pima” from MASS package airquality (find the package) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
